{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Kaggle Competition](https://www.kaggle.com/c/nfl-big-data-bowl-2021)\n",
    "\n",
    "Intent is to look into passing stats of targeted receiver vs. defender to see if physical traits differences between the two are important when determining defensive success.\n",
    "\n",
    "1. May need to only look at man coverage for this - build model to predict man vs. zone scheme based on labeled data so that entirety of season play data can be used?\n",
    "2. Include speed/agility as a differentiator? Will need to determine max speed/accel of players from full season tracking data\n",
    "3. May need to find and exclude plays thrown into double coverage (i.e. second defender close to ball)\n",
    "4. Calculate stats like passer rating for combinations, heat map for height-weight difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "1. For plays, remove typeDropback == UNKNOWN when applying man/zone model (either spike, or trick plays on special teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add local directory to import path\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('.'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.optimize as optim\n",
    "\n",
    "import joblib\n",
    "\n",
    "# local import \n",
    "import nflutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_df = pd.read_csv('csv/plays.csv')\n",
    "game_df = pd.read_csv('csv/games.csv')\n",
    "player_df = pd.read_csv('csv/players.csv')\n",
    "target_df = pd.read_csv('csv/targetedReceiver.csv')\n",
    "coverage_df = pd.read_csv('csv/coverages_week1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the zone classifier\n",
    "clf_zone = joblib.load('zone_classifier.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_num = 15\n",
    "\n",
    "track_df = pd.read_csv(f'csv/week{week_num}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call out bad plays to remove from analysis\n",
    "\n",
    "1. gameId = 2018102101, playId = 3078: Offense positions are clearly wrong at start and during play\n",
    "2. gameId = 2018092301, playId = 477: SS Jefferson position jumps around and is intermittent during play\n",
    "2. gameId = 2018092301, playId = 949: Same as play 477"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1    False\n",
       "2    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=pd.DataFrame({'a': [1,2,3], 'b':[4,5,6]})\n",
    "a[['a','b']].apply(tuple,1).isin([(1,4), (1,5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of (gameId, playId)\n",
    "bad_plays = [(2018102101, 3078),\n",
    "             (2018092301, 477),\n",
    "             (2018092301, 949)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Determine the closest defender to each play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the closest defender when the ball arrives at the receiver\n",
    "def closest_defender(track_df, game_df, play_df):\n",
    "    # returns the nflId of the defensive player closest to the targeted player at the resolution of the pass attempt\n",
    "    cd_series = pd.Series([np.nan, np.nan], index=['nflId_def', 'dist_def'])\n",
    "    \n",
    "    # get the current play gameId and playId\n",
    "    game_id = track_df.gameId.iloc[0]\n",
    "    play_id = track_df.playId.iloc[0]\n",
    "    \n",
    "    # determine who has the ball (team code)\n",
    "    home_abbr = game_df[game_df.gameId==game_id].iloc[0]['homeTeamAbbr']\n",
    "    away_abbr = game_df[game_df.gameId==game_id].iloc[0]['visitorTeamAbbr']\n",
    "    \n",
    "    abbr_possess = play_df[(play_df.gameId==game_id) & (play_df.playId==play_id)].iloc[0]['possessionTeam']\n",
    "    \n",
    "    if abbr_possess == home_abbr:\n",
    "        team_poss = 'home'\n",
    "        team_def = 'away'\n",
    "    else:\n",
    "        team_poss = 'away'\n",
    "        team_def = 'home'\n",
    "    \n",
    "    if np.any(track_df.targetNflId.isna()):\n",
    "        # no targeted receiver data for this play, return NaN\n",
    "        return cd_series\n",
    "    \n",
    "    # constants\n",
    "#     DEF_POSITIONS = ['DE', 'DL', 'NT', 'LB', 'MLB', 'ILB', 'OLB', 'DB', 'CB', 'FS', 'SS', 'S']\n",
    "    PASS_END_EVENTS = ['pass_arrived',\n",
    "                       'pass_outcome_interception',\n",
    "                       'pass_outcome_incomplete',\n",
    "                       'pass_outcome_caught']\n",
    "    # find the frameId of the earliest of the pass end events\n",
    "    # - account for errors on individual players: group by event, find the median frame for each event, then\n",
    "    #   take the minimum of the medians to get the first event (essentially voting then min)\n",
    "    frame_id = track_df.loc[track_df.event.isin(PASS_END_EVENTS), ['event', 'frameId']].groupby('event').median().min().iloc[0]\n",
    "    if np.isnan(frame_id):\n",
    "        return cd_series  # no frame to choose closest defender, return nan\n",
    "    \n",
    "    # get the data of the applicable frame\n",
    "    frame_df = track_df[track_df.frameId == frame_id]\n",
    "    \n",
    "    # get the location of the targeted receiver\n",
    "    if not np.any(frame_df.nflId == frame_df.targetNflId):\n",
    "        # no target data for the play, discard\n",
    "        return cd_series\n",
    "    \n",
    "    # QB throwaways consider the target the QB. If this is the case, do not consider closest defender.\n",
    "    tgt_position = frame_df.loc[frame_df.nflId == frame_df.targetNflId, 'position'].iloc[0]\n",
    "    if tgt_position == 'QB':\n",
    "        return cd_series\n",
    "    \n",
    "    x_tgt = frame_df.loc[frame_df.nflId == frame_df.targetNflId, 'x'].iloc[0]\n",
    "    y_tgt = frame_df.loc[frame_df.nflId == frame_df.targetNflId, 'y'].iloc[0]\n",
    "\n",
    "    \n",
    "    # get the location of defenders\n",
    "    if not np.any(frame_df.team == team_def):\n",
    "        # no defender data - return nan\n",
    "        return cd_series\n",
    "    \n",
    "    nfl_id_def = frame_df.loc[frame_df.team == team_def, 'nflId'].to_numpy()\n",
    "    x_def = frame_df.loc[frame_df.team == team_def, 'x'].to_numpy()\n",
    "    y_def = frame_df.loc[frame_df.team == team_def, 'y'].to_numpy()\n",
    "    \n",
    "    # calculate the distance between the defenders and the targeted receiver\n",
    "    dist_def = np.sqrt((x_def - x_tgt)**2 + (y_def - y_tgt)**2)\n",
    "    \n",
    "    # determine the closest defender to the ball\n",
    "    try:\n",
    "        idx_min = np.argmin(dist_def)\n",
    "    except Exception as err:\n",
    "        print(frame_df)\n",
    "        raise err\n",
    "    \n",
    "    # return ID and distance for closest defender\n",
    "    cd_series['nflId_def'] = nfl_id_def[idx_min]\n",
    "    cd_series['dist_def'] = dist_def[idx_min]\n",
    "    return cd_series\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the closest defender when the ball arrives at the receiver\n",
    "def depth_of_pass(track_df):\n",
    "    \n",
    "    # transform the directionality of the data\n",
    "    play_track_df = nflutil.transform_tracking_data(track_df)\n",
    "    \n",
    "    # returns the nflId of the defensive player closest to the targeted player at the resolution of the pass attempt\n",
    "    pass_depth = np.nan\n",
    "    \n",
    "    if np.any(play_track_df.targetNflId.isna()):\n",
    "        # no targeted receiver data for this play, return NaN\n",
    "        return np.nan\n",
    "    \n",
    "    # constants\n",
    "    PASS_END_EVENTS = ['pass_arrived',\n",
    "                       'pass_outcome_interception',\n",
    "                       'pass_outcome_incomplete',\n",
    "                       'pass_outcome_caught']\n",
    "    # find the frameId of the earliest of the pass end events\n",
    "    # - account for errors on individual players: group by event, find the median frame for each event, then\n",
    "    #   take the minimum of the medians to get the first event (essentially voting then min)\n",
    "    frame_id = (play_track_df.loc[play_track_df.event.isin(PASS_END_EVENTS), ['event', 'frameId']]\n",
    "                .groupby('event')\n",
    "                .median().min().iloc[0])\n",
    "    \n",
    "    if np.isnan(frame_id):\n",
    "        return np.nan  # no frame to choose closest defender, return nan\n",
    "    \n",
    "    # get the data of the applicable frame\n",
    "    frame_df = play_track_df[play_track_df.frameId == frame_id].copy()\n",
    "    \n",
    "    # get the location of the targeted receiver\n",
    "    if not np.any(frame_df.nflId == frame_df.targetNflId):\n",
    "        # no target data for the play, discard\n",
    "        return np.nan\n",
    "    \n",
    "    # QB throwaways consider the target the QB. If this is the case, do not consider closest defender.\n",
    "    tgt_position = frame_df.loc[frame_df.nflId == frame_df.targetNflId, 'position'].iloc[0]\n",
    "    if tgt_position == 'QB':\n",
    "        return np.nan\n",
    "    \n",
    "    # get x-coordinate of the line of scrimmage (in normalized direction)\n",
    "    x_los = play_track_df.x[(play_track_df.team == 'football') & (play_track_df.frameId == 1)].iloc[0]\n",
    "    \n",
    "    # save the distance downfield of all observations relative to the line of scrimmage\n",
    "    frame_df['depth'] = frame_df['x'] - x_los\n",
    "    \n",
    "    depth_tgt = frame_df.loc[frame_df.nflId == frame_df.targetNflId, 'depth'].iloc[0]\n",
    "#     depth_football = frame_df.loc[frame_df.team == 'football', 'depth'].iloc[0]\n",
    "    \n",
    "    # return the depth of the target\n",
    "    return depth_tgt\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the function for a given play:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>s</th>\n",
       "      <th>a</th>\n",
       "      <th>dis</th>\n",
       "      <th>o</th>\n",
       "      <th>dir</th>\n",
       "      <th>event</th>\n",
       "      <th>nflId</th>\n",
       "      <th>displayName</th>\n",
       "      <th>jerseyNumber</th>\n",
       "      <th>position</th>\n",
       "      <th>frameId</th>\n",
       "      <th>team</th>\n",
       "      <th>gameId</th>\n",
       "      <th>playId</th>\n",
       "      <th>playDirection</th>\n",
       "      <th>route</th>\n",
       "      <th>targetNflId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-14T01:23:55.400Z</td>\n",
       "      <td>79.82</td>\n",
       "      <td>24.76</td>\n",
       "      <td>4.95</td>\n",
       "      <td>2.71</td>\n",
       "      <td>0.50</td>\n",
       "      <td>159.18</td>\n",
       "      <td>152.45</td>\n",
       "      <td>None</td>\n",
       "      <td>496723.0</td>\n",
       "      <td>Eric Berry</td>\n",
       "      <td>29.0</td>\n",
       "      <td>SS</td>\n",
       "      <td>1</td>\n",
       "      <td>home</td>\n",
       "      <td>2018121300</td>\n",
       "      <td>84</td>\n",
       "      <td>left</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2553913.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-14T01:23:55.400Z</td>\n",
       "      <td>89.06</td>\n",
       "      <td>22.81</td>\n",
       "      <td>1.74</td>\n",
       "      <td>4.09</td>\n",
       "      <td>0.20</td>\n",
       "      <td>253.90</td>\n",
       "      <td>199.21</td>\n",
       "      <td>None</td>\n",
       "      <td>2495288.0</td>\n",
       "      <td>Virgil Green</td>\n",
       "      <td>88.0</td>\n",
       "      <td>TE</td>\n",
       "      <td>1</td>\n",
       "      <td>away</td>\n",
       "      <td>2018121300</td>\n",
       "      <td>84</td>\n",
       "      <td>left</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2553913.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-14T01:23:55.400Z</td>\n",
       "      <td>86.28</td>\n",
       "      <td>32.45</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>122.22</td>\n",
       "      <td>69.31</td>\n",
       "      <td>None</td>\n",
       "      <td>2495493.0</td>\n",
       "      <td>Justin Houston</td>\n",
       "      <td>50.0</td>\n",
       "      <td>OLB</td>\n",
       "      <td>1</td>\n",
       "      <td>home</td>\n",
       "      <td>2018121300</td>\n",
       "      <td>84</td>\n",
       "      <td>left</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2553913.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-14T01:23:55.400Z</td>\n",
       "      <td>91.54</td>\n",
       "      <td>27.30</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>275.04</td>\n",
       "      <td>341.42</td>\n",
       "      <td>None</td>\n",
       "      <td>2506121.0</td>\n",
       "      <td>Philip Rivers</td>\n",
       "      <td>17.0</td>\n",
       "      <td>QB</td>\n",
       "      <td>1</td>\n",
       "      <td>away</td>\n",
       "      <td>2018121300</td>\n",
       "      <td>84</td>\n",
       "      <td>left</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2553913.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-14T01:23:55.400Z</td>\n",
       "      <td>79.44</td>\n",
       "      <td>44.93</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.03</td>\n",
       "      <td>85.63</td>\n",
       "      <td>319.27</td>\n",
       "      <td>None</td>\n",
       "      <td>2530794.0</td>\n",
       "      <td>Ron Parker</td>\n",
       "      <td>38.0</td>\n",
       "      <td>FS</td>\n",
       "      <td>1</td>\n",
       "      <td>home</td>\n",
       "      <td>2018121300</td>\n",
       "      <td>84</td>\n",
       "      <td>left</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2553913.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time      x      y     s     a   dis       o     dir  \\\n",
       "0  2018-12-14T01:23:55.400Z  79.82  24.76  4.95  2.71  0.50  159.18  152.45   \n",
       "1  2018-12-14T01:23:55.400Z  89.06  22.81  1.74  4.09  0.20  253.90  199.21   \n",
       "2  2018-12-14T01:23:55.400Z  86.28  32.45  0.01  0.01  0.00  122.22   69.31   \n",
       "3  2018-12-14T01:23:55.400Z  91.54  27.30  0.11  0.09  0.00  275.04  341.42   \n",
       "4  2018-12-14T01:23:55.400Z  79.44  44.93  0.33  0.41  0.03   85.63  319.27   \n",
       "\n",
       "  event      nflId     displayName  jerseyNumber position  frameId  team  \\\n",
       "0  None   496723.0      Eric Berry          29.0       SS        1  home   \n",
       "1  None  2495288.0    Virgil Green          88.0       TE        1  away   \n",
       "2  None  2495493.0  Justin Houston          50.0      OLB        1  home   \n",
       "3  None  2506121.0   Philip Rivers          17.0       QB        1  away   \n",
       "4  None  2530794.0      Ron Parker          38.0       FS        1  home   \n",
       "\n",
       "       gameId  playId playDirection route  targetNflId  \n",
       "0  2018121300      84          left   NaN    2553913.0  \n",
       "1  2018121300      84          left   NaN    2553913.0  \n",
       "2  2018121300      84          left   NaN    2553913.0  \n",
       "3  2018121300      84          left   NaN    2553913.0  \n",
       "4  2018121300      84          left   NaN    2553913.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_id = 2018121300\n",
    "play_id = 84\n",
    "x = pd.merge(track_df[(track_df.gameId == game_id) & (track_df.playId == play_id)], target_df, \n",
    "             how='left', on=['gameId','playId'])\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nflId_def    2.552265e+06\n",
       "dist_def     5.889822e-01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_defender(x, game_df, play_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.110000000000007"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_of_pass(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate list of closest defenders and coverage type for all plays in the season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_play_features(play_track_df, game_df, play_df, t_defender_thresh=1.5, t_scheme_develop=4, t_reaction_time=0):\n",
    "    ### THE INPUT TRACKING DATA MUST BE NORMALIZED FOR DIRECTION BEFORE INPUT INTO THIS FUNCTION\n",
    "    # inputs:\n",
    "    #     - play_track_df: DataFrame of the raw player tracking data for an individual play.\n",
    "    #                      MUST ONLY BE FOR A SINGLE PLAY, CANNOT HANDLE MULTIPLE PLAYS.\n",
    "    #     - t_defender_thresh: time in seconds after the snap to determine which players are in coverage\n",
    "    #     - t_scheme_develop: time in seconds after the snap to set as a max time threshold\n",
    "    #                         (i.e. before the play breaks down, after which the movement \n",
    "    #                          is not always indicative of the coverage scheme)\n",
    "    #     - t_reaction_time: time in seconds after the ball thrown to continue taking statistics (paths\n",
    "    #                        won't change until players realize the ball has been thrown)\n",
    "    \n",
    "    # local constants\n",
    "    DEF_DEEP_THRESH = 10  # yards behind the line of scrimmage considered \"deep\" coverage\n",
    "\n",
    "    # work on a copy of the data rather than the actual data (for temporary features)\n",
    "    play_track_df = play_track_df.copy().drop_duplicates()\n",
    "    \n",
    "    # get the current play gameId and playId\n",
    "    game_id = play_track_df.gameId.iloc[0]\n",
    "    play_id = play_track_df.playId.iloc[0]\n",
    "    \n",
    "    # determine who has the ball (team code)\n",
    "    home_abbr = game_df[game_df.gameId==game_id].iloc[0]['homeTeamAbbr']\n",
    "    away_abbr = game_df[game_df.gameId==game_id].iloc[0]['visitorTeamAbbr']\n",
    "\n",
    "    \n",
    "    abbr_possess = play_df[(play_df.gameId==game_id) & (play_df.playId==play_id)].iloc[0]['possessionTeam']\n",
    "    \n",
    "    if abbr_possess == home_abbr:\n",
    "        team_poss = 'home'\n",
    "        team_def = 'away'\n",
    "    else:\n",
    "        team_poss = 'away'\n",
    "        team_def = 'home'\n",
    "        \n",
    " \n",
    "    # ------------- FEATURE GENERATION SETUP/INTERMEDIATE CALCULATIONS ----------------------\n",
    "     \n",
    "    # get play information\n",
    "    x_los = play_track_df.x[(play_track_df.team == 'football') & (play_track_df.frameId == 1)].iloc[0]\n",
    "    \n",
    "    # save the distance downfield of all observations relative to the line of scrimmage\n",
    "    play_track_df['depth'] = play_track_df['x'] - x_los\n",
    "    \n",
    "    # get frameId for specific points in the play (exclude handoff: not a material pivot part of the play,\n",
    "    # also sometimes occurs prior to the snap)\n",
    "    pivot_events = ['pass_forward', 'qb_sack', 'fumble', 'qb_strip_sack', 'pass_shovel']\n",
    "    \n",
    "    frame_max = play_track_df.frameId.max()\n",
    "    frame_snap = play_track_df[play_track_df.event=='ball_snap']['frameId'].iloc[0]\n",
    "    if np.any(play_track_df.event.isin(pivot_events)):\n",
    "        # find the frameId of the earliest of the pivot events\n",
    "        # - account for errors on individual players: group by event, find the median frame for each event, then\n",
    "        #   take the minimum of the medians to get the first event (essentially voting then min)\n",
    "        frame_pivot = (play_track_df.loc[play_track_df.event.isin(pivot_events), ['event', 'frameId']]\n",
    "                       .groupby('event').median().min().iloc[0]\n",
    "                       + int(round(10 * t_reaction_time)))\n",
    "    else:\n",
    "        frame_pivot = frame_max\n",
    "    \n",
    "    # save important frameId's in the play:\n",
    "    frame_start = frame_snap\n",
    "    frame_cover_freeze = min(frame_max, frame_pivot, int(round(frame_snap + 10*t_defender_thresh)))\n",
    "    frame_scheme_develop = int(frame_snap + round(10*t_scheme_develop))\n",
    "    frame_end = min(frame_pivot, frame_scheme_develop, frame_max)\n",
    "    \n",
    "    \n",
    "    # filter out data from frames outside of the range (frame_start <= F <= frame_end)\n",
    "    play_track_df = play_track_df[(play_track_df.frameId >= frame_start) & (play_track_df.frameId <= frame_end)]\n",
    "    \n",
    "    \n",
    "    # ----- SAVE SLICES OF DATAFRAME FOR DEFENDERS AND COVERAGE AND ELIGIBLE RECEIVERS ----\n",
    "    \n",
    "    ### get defensive player tracks that are in coverage (i.e. not blitzing/rushing the passer)\n",
    "    cover_players = play_track_df.nflId[(play_track_df.frameId == frame_cover_freeze) &\n",
    "                          (play_track_df.team == team_def) & \n",
    "                          (play_track_df.depth > 0)]\n",
    "    def_track = play_track_df[play_track_df.nflId.isin(cover_players)].pivot(\n",
    "        index='frameId', columns='nflId', values=['x', 'depth', 'y', 's', 'a', 'dir', 'o'])\n",
    "    \n",
    "    ### get offensive player tracks of eligible receivers (minus QB)\n",
    "    # all players\n",
    "    off_track = play_track_df[(play_track_df.team == team_poss) & (play_track_df.position != 'QB')].pivot(\n",
    "        index='frameId', columns='nflId', values=['x', 'depth', 'y', 's', 'a', 'dir', 'o'])\n",
    "    \n",
    "    # players downfield (depth > 0)\n",
    "    downfield_players = play_track_df.nflId[(play_track_df.frameId == frame_cover_freeze) &\n",
    "                          (play_track_df.team == team_poss) & \n",
    "                          (play_track_df.depth > 0)]\n",
    "    # edge case where there are no downfield receivers at the time of throw: quick screen,\n",
    "    # goal-line, etc. --> classify all offensive players as \"downfield\"\n",
    "    if len(downfield_players) == 0:\n",
    "        downfield_players = play_track_df.nflId[(play_track_df.frameId == frame_cover_freeze) &\n",
    "                          (play_track_df.team == team_poss) &\n",
    "                          (play_track_df.position != 'QB')]\n",
    "    \n",
    "    downfield_track = play_track_df[play_track_df.nflId.isin(downfield_players)].pivot(\n",
    "        index='frameId', columns='nflId', values=['x', 'depth', 'y', 's', 'a', 'dir', 'o'])\n",
    "    \n",
    "    # ----- OUTERMOST OFF-DEF MATCHUP FEATURES --------------------------------------------------------\n",
    "    \n",
    "    # get attributes for the outermost receivers and defenders at the snap to identify \n",
    "    # coverage as inside or outside technique\n",
    "    \n",
    "    # identify outermost defenders at snap (get corresponding array column index)\n",
    "    min_def_y_idx = play_track_df.loc[(play_track_df.frameId == frame_snap) &\n",
    "                              (play_track_df.team == team_def), 'y'].idxmin()\n",
    "    max_def_y_idx = play_track_df.loc[(play_track_df.frameId == frame_snap) &\n",
    "                              (play_track_df.team == team_def), 'y'].idxmax()\n",
    "    right_def_nfl_id = play_track_df.nflId.loc[min_def_y_idx]\n",
    "    left_def_nfl_id = play_track_df.nflId.loc[max_def_y_idx]\n",
    "    \n",
    "    # get outermost defender at snap X- and Y-coordinates during the play\n",
    "    outer_def_x = np.hstack([play_track_df.x[play_track_df.nflId == left_def_nfl_id].to_numpy().reshape(-1,1),\n",
    "                            play_track_df.x[play_track_df.nflId == right_def_nfl_id].to_numpy().reshape(-1,1)])\n",
    "    outer_def_y = np.hstack([play_track_df.y[play_track_df.nflId == left_def_nfl_id].to_numpy().reshape(-1,1),\n",
    "                            play_track_df.y[play_track_df.nflId == right_def_nfl_id].to_numpy().reshape(-1,1)])\n",
    "    \n",
    "    # identify outermost receivers at snap (get corresponding array column index)\n",
    "    min_off_y_idx = play_track_df.loc[(play_track_df.frameId == frame_snap) &\n",
    "                              (play_track_df.team == team_poss), 'y'].idxmin()\n",
    "    max_off_y_idx = play_track_df.loc[(play_track_df.frameId == frame_snap) &\n",
    "                              (play_track_df.team == team_poss), 'y'].idxmax()\n",
    "    right_off_nfl_id = play_track_df.nflId.loc[min_off_y_idx]\n",
    "    left_off_nfl_id = play_track_df.nflId.loc[max_off_y_idx]\n",
    "    \n",
    "    # get outermost receiver at snap X- and Y-coordinates during the play\n",
    "    outer_off_x = np.hstack([play_track_df.x[play_track_df.nflId == left_off_nfl_id].to_numpy().reshape(-1,1),\n",
    "                            play_track_df.x[play_track_df.nflId == right_off_nfl_id].to_numpy().reshape(-1,1)])\n",
    "    outer_off_y = np.hstack([play_track_df.y[play_track_df.nflId == left_off_nfl_id].to_numpy().reshape(-1,1),\n",
    "                            play_track_df.y[play_track_df.nflId == right_off_nfl_id].to_numpy().reshape(-1,1)])\n",
    "    outer_off_dis = np.hstack([play_track_df.dis[play_track_df.nflId == left_off_nfl_id].to_numpy().reshape(-1,1),\n",
    "                            play_track_df.dis[play_track_df.nflId == right_off_nfl_id].to_numpy().reshape(-1,1)])\n",
    "    \n",
    "    # -- Determine if the defender shadows outside or inside of the outer receiver:\n",
    "    # -- inner likely man, outer likely zone. look at snap and aggregate until throw\n",
    "    \n",
    "    # distance from the middle of the field \n",
    "    dist_def_mid = np.abs(53.3/2 - outer_def_y)\n",
    "    dist_off_mid = np.abs(53.3/2 - outer_off_y)\n",
    "    # def - off: positive if defender is outside, negative if defender is inside\n",
    "    dist_shadow_out = dist_def_mid - dist_off_mid\n",
    "\n",
    "    # aggregate over play (mean offset inside or outside)\n",
    "    dist_shadow_out_play = np.nanmean(dist_shadow_out, axis=0)\n",
    "    \n",
    "    # ------ PLAY CHARACTERISTICS AT SPECIFIC FRAMES/POINTS IN TIME -----------------------\n",
    "    \n",
    "    # find characteristics of scheme at the snap (line of scrimmage naturally divides offense + defense)\n",
    "    cb_id = play_track_df[play_track_df.position=='CB']['nflId'].unique()\n",
    "    n_cb = len(cb_id)\n",
    "    \n",
    "    if n_cb > 0:\n",
    "        # depth at snap\n",
    "        cb_depth_at_snap = play_track_df.loc[(play_track_df.frameId == frame_start) \n",
    "                                             & (play_track_df.nflId.isin(cb_id)), 'depth']\n",
    "        \n",
    "    \n",
    "    # find characteristics of players in coverage at the \"cover freeze time\"\n",
    "    n_deep_freeze = np.sum((play_track_df.nflId.isin(cover_players)) & \n",
    "                           (play_track_df.depth >= DEF_DEEP_THRESH) &\n",
    "                           (play_track_df.frameId == frame_cover_freeze)) \n",
    "    \n",
    "    \n",
    "    # ------GENERATE FEATURES FOR EACH COVERAGE PLAYER AT EACH FRAME ---------------------\n",
    "    \n",
    "    feature_data = {'depth_mean': [],\n",
    "                    'speed_var': [],\n",
    "                    'off_mean': [],\n",
    "                   }\n",
    "    \n",
    "    # data that is not dependent on the specific player\n",
    "    x_off = off_track['x'].to_numpy()  # (n_frame, n_off) array\n",
    "    y_off = off_track['y'].to_numpy()  # (n_frame, n_off) array\n",
    "    x_def_full = def_track['x'].to_numpy()  # (n_frame, n_def) array\n",
    "    y_def_full = def_track['y'].to_numpy()  # (n_frame, n_def) array\n",
    "    \n",
    "    \n",
    "    ### --- loop over each cover player (defense) ---------------------------------------\n",
    "    for i, player in enumerate(cover_players):\n",
    "        x_player = def_track['x'][player].to_numpy().reshape(-1, 1)  # (n_frame,1) array\n",
    "        depth_player = def_track['depth'][player].to_numpy().reshape(-1, 1)  # (n_frame,1) array\n",
    "        y_player = def_track['y'][player].to_numpy().reshape(-1, 1)  # (n_frame,1) array\n",
    "        s_player = def_track['s'][player].to_numpy().reshape(-1, 1)  # (n_frame,1) array\n",
    "\n",
    "        # calculate distance to each player at each time\n",
    "        dist_off = np.sqrt((x_player - x_off)**2 + (y_player - y_off)**2)  # (n_frame, n_off) array\n",
    "        dist_off_min = np.nanmin(dist_off, axis=1) # (n_frame,) array\n",
    "        if np.any(np.isnan(dist_off_min)):\n",
    "            print(f'WARNING: All-nan row found in dist_off_min for gameId = {game_id}, playId = {play_id}')\n",
    "        \n",
    "        # save average distance\n",
    "        feature_data['depth_mean'].append(np.nanmean(depth_player))\n",
    "        feature_data['speed_var'].append(np.nanvar(s_player))\n",
    "        feature_data['off_mean'].append(np.nanmean(dist_off_min))\n",
    "        \n",
    "    # put results into a dataframe\n",
    "    def_df = pd.DataFrame(feature_data, index=cover_players)\n",
    "    \n",
    "    \n",
    "    ### -- loop over each downfield offensive player  (offense) ----------------------\n",
    "    downfield_data = {\n",
    "        'df_rec_space_mean': [],\n",
    "    }\n",
    "    \n",
    "    for i, player in enumerate(downfield_players):\n",
    "        # extract location of player and put as column vector\n",
    "        x_player = downfield_track['x'][player].to_numpy().reshape(-1, 1)  # (n_frame,1) array\n",
    "        y_player = downfield_track['y'][player].to_numpy().reshape(-1, 1)  # (n_frame,1) array\n",
    "        \n",
    "        # calculate distance to each defensive at each time\n",
    "        dist_to_defender = np.sqrt((x_player - x_def_full)**2 + (y_player - y_def_full)**2)  # (n_frame, n_def) array\n",
    "        # get distance to closest defender\n",
    "        dist_to_defender_min = np.nanmin(dist_to_defender, axis=1) # (n_frame,) array\n",
    "        if np.any(np.isnan(dist_to_defender_min)):\n",
    "            print(f'WARNING: All-nan row found in dist_to_defender_min for gameId = {game_id}, playId = {play_id}')\n",
    "        \n",
    "        # save average of distance to closest defender\n",
    "        downfield_data['df_rec_space_mean'].append(np.nanmean(dist_to_defender_min))\n",
    "    \n",
    "    # put results into a dataframe\n",
    "    downfield_df = pd.DataFrame(downfield_data, index=downfield_players)\n",
    "    \n",
    "    \n",
    "    # ----------- COLLECT ALL FEATURES INTO OUTPUT SERIES -------------------------\n",
    "    \n",
    "    # return averages of features generated from applicable players, for play-level feature\n",
    "    out_data = pd.concat([def_df.mean(), downfield_df.mean()])\n",
    "    \n",
    "    # add in number of deep defenders at the \"freeze frame\"\n",
    "    out_data['n_deep_frz'] = n_deep_freeze\n",
    "    \n",
    "    # add in inside-outside technique feature\n",
    "    out_data['dist_shadow_out_play_mean'] = np.mean(dist_shadow_out_play)\n",
    "    \n",
    "    # add in CB-specific feature (depth at snap of all cornerbacks)\n",
    "    if n_cb > 0:\n",
    "        out_data['cb_depth_snap_min'] = np.nanmin(cb_depth_at_snap)\n",
    "    else:\n",
    "        out_data['cb_depth_snap_min'] = 0\n",
    "        \n",
    "    return out_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_zone_predict_dataframe(clf_zone, track_df, game_df, play_df,\n",
    "                             t_scheme_develop=4, t_reaction_time=0,\n",
    "                            coverage_df=None, bad_plays=None):\n",
    "    \n",
    "    # remove bad plays (if provided)\n",
    "    if bad_plays is not None and len(bad_plays) > 0:\n",
    "        track_df = track_df[~track_df[['gameId','playId']].apply(tuple, 1).isin(bad_plays)]\n",
    "    \n",
    "    # filter out any plays that are missing an entire team (does occur in the dataset where the defense is missing:\n",
    "    # 3 is for 'home', 'away', and 'football')\n",
    "    track_df = track_df.groupby(['gameId','playId']).filter(lambda df: len(df.team.unique()) == 3)\n",
    "    \n",
    "    # filter out spike plays\n",
    "    track_df = track_df.groupby(['gameId','playId']).filter(lambda df: np.all(df.event != 'qb_spike'))\n",
    "    \n",
    "    # Transform the raw tracking data so that all offensive plays face the same direction,\n",
    "    # group the tracking data for each play together\n",
    "    test_df_group = nflutil.transform_tracking_data(track_df).groupby(['gameId', 'playId'])\n",
    "\n",
    "    # ------ Create the features for each play ---------------------\n",
    "    feature_df = pd.DataFrame()\n",
    "\n",
    "    col_names = []\n",
    "    values = []\n",
    "\n",
    "    # loop over each play\n",
    "    for (loop_game_id, loop_play_id), loop_track_df in test_df_group:\n",
    "\n",
    "        # error block for easier debugging if a particular play runs into an error\n",
    "        try:\n",
    "            features = create_play_features(loop_track_df,\n",
    "                                            game_df,\n",
    "                                            play_df,\n",
    "                                            t_scheme_develop=t_scheme_develop,\n",
    "                                            t_reaction_time=t_reaction_time)\n",
    "        except Exception as err:\n",
    "            print(f'error in gameId {loop_game_id}, playId {loop_play_id}')\n",
    "            raise err\n",
    "\n",
    "        # first loop: save the output dataframe column names (gameId, playId, all feature names)\n",
    "        if not col_names: # empty\n",
    "            col_names.extend(['gameId', 'playId'])\n",
    "            col_names.extend(features.index.tolist())\n",
    "\n",
    "        # save the gameId, playId, and all feature values into a list\n",
    "        loop_values = [loop_game_id, loop_play_id]\n",
    "        loop_values.extend(features.values.tolist())\n",
    "        values.append(loop_values)\n",
    "\n",
    "    # convert the features into a dataframe (1 row per play), inner join on plays with labeled coverages\n",
    "    feature_df = pd.DataFrame(values, columns=col_names)\n",
    "    \n",
    "    # create zone-labeled plays\n",
    "    labeled_play_df = feature_df.copy()\n",
    "\n",
    "    # make predictions\n",
    "    labeled_play_df['zone'] = clf_zone.predict(feature_df.drop(columns=['gameId','playId']))\n",
    "    \n",
    "    # if the actual labels are known, set the plays to those values\n",
    "    if coverage_df is not None:\n",
    "        # classify the actual coverage as man or zone\n",
    "        temp_df = coverage_df.copy()\n",
    "        temp_df['zone'] = np.nan  # initialize all as nan\n",
    "        temp_df.loc[temp_df.coverage.str.contains('Zone'), 'zone'] = 1\n",
    "        temp_df.loc[temp_df.coverage.str.contains('Man'), 'zone'] = 0\n",
    "        \n",
    "        if np.sum(temp_df.zone.isna()) > 0:\n",
    "            raise ValueError('coverage_df contains a value in the \"coverage\" field that does not contain \"Man\" or \"Zone\"')\n",
    "        \n",
    "        \n",
    "        # overwrite particular plays with known values\n",
    "        known_coverage_idx = pd.MultiIndex.from_frame(temp_df[['gameId','playId']])\n",
    "        labeled_play_df.set_index(['gameId','playId'], inplace=True)\n",
    "        labeled_play_df.loc[known_coverage_idx, 'zone'] = temp_df['zone'].to_numpy()\n",
    "        # set index back to original\n",
    "        labeled_play_df.reset_index(inplace=True)\n",
    "\n",
    "    \n",
    "    # return the feature dataframe\n",
    "    return labeled_play_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loop through weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing tracking data for week 1...\n",
      "Analyzing tracking data for week 2...\n",
      "Analyzing tracking data for week 3...\n",
      "Analyzing tracking data for week 4...\n",
      "Analyzing tracking data for week 5...\n",
      "Analyzing tracking data for week 6...\n",
      "Analyzing tracking data for week 7...\n",
      "Analyzing tracking data for week 8...\n",
      "Analyzing tracking data for week 9...\n",
      "Analyzing tracking data for week 10...\n",
      "Analyzing tracking data for week 11...\n",
      "Analyzing tracking data for week 12...\n",
      "Analyzing tracking data for week 13...\n",
      "Analyzing tracking data for week 14...\n"
     ]
    }
   ],
   "source": [
    "processed_weeks = []  # list of DataFrames containing processed data\n",
    "zone_predict = []  # list of DataFrames containing zone prediction data\n",
    "\n",
    "max_week = 17\n",
    "\n",
    "for week in range(1,max_week+1):  # weeks 1-17\n",
    "    print(f'Analyzing tracking data for week {week}...')\n",
    "    # load tracking data\n",
    "    temp_track_df = pd.read_csv(f'csv/week{week}.csv')\n",
    "    # add the targeted receiver to the tracking data dataframe\n",
    "    temp_track_df = pd.merge(temp_track_df, target_df, how='left', on=['gameId', 'playId'])\n",
    "    # calculate closest defender\n",
    "    closest_def = temp_track_df.groupby(['gameId','playId']).apply(closest_defender, game_df, play_df).reset_index()\n",
    "    # calculate depth of pass\n",
    "    dop_df = temp_track_df.groupby(['gameId','playId']).apply(depth_of_pass).reset_index()\n",
    "    dop_df.rename(columns={0: 'pass_depth'}, inplace=True)\n",
    "    # combine into single dataframe\n",
    "    processed_weeks.append(pd.merge(closest_def, dop_df, on=['gameId','playId']))\n",
    "    \n",
    "    # predict man/zone coverage\n",
    "    if week == 1:\n",
    "        zone_df = create_zone_predict_dataframe(clf_zone, temp_track_df, game_df, play_df, coverage_df=coverage_df,\n",
    "                                               bad_plays=bad_plays)\n",
    "    else:\n",
    "        # no known coverage\n",
    "        zone_df = create_zone_predict_dataframe(clf_zone, temp_track_df, game_df, play_df,\n",
    "                                               bad_plays=bad_plays)\n",
    "        \n",
    "    zone_predict.append(zone_df)\n",
    "    \n",
    "    \n",
    "print('Loop complete.')\n",
    "# concatenate into a full matrix\n",
    "closest_def_df = pd.concat(processed_weeks, ignore_index=True)\n",
    "# remove \"special\" plays\n",
    "closest_def_df.set_index(['gameId','playId'], inplace=True)\n",
    "valid_plays_mi = pd.MultiIndex.from_frame(play_df.loc[play_df.typeDropback!='UNKNOWN', ['gameId','playId']])\n",
    "closest_def_df = closest_def_df.loc[valid_plays_mi]\n",
    "closest_def_df.reset_index(inplace=True)\n",
    "\n",
    "# concatenate zone dataframes\n",
    "zone_def_df = pd.concat(zone_predict, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create base dataframe for pass play characteristics\n",
    "pass_df = pd.merge(closest_def_df, zone_def_df,\n",
    "                          how='left',\n",
    "                          on=['gameId','playId'])\n",
    "pass_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Distribution of dist_def:')\n",
    "pass_df['dist_def'].describe(percentiles=[.25, .5, .75, .9, .95, .97, .98, .99, .995])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Distribution of dist_def when depth_mean > 15:')\n",
    "pass_df.loc[pass_df.depth_mean > 15, 'dist_def'].describe(percentiles=[.25, .5, .75, .9, .95, .97])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over 99.5% of the cases are below 15 yards to the closest defender. This is a reasonable cutoff for downstream analysis so that prevent or soft zone (coverages designed to give up yards but not points) does not count against an individual's performance, since filtering the mean defensive team depth of over 15 yards during the play has a closest defender distance of under 15 yards 90% of the time as well (signifying soft coverage but not prevent). Therefore removing all cases above 15 yards to the closest defender effectively filters out the vast majority of prevent defense plays where there is no real attempt to force an incompletion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag scenarios where the closest individual is not really attempting to cause an incompletion\n",
    "dist_def_cutoff = 15\n",
    "pass_df['covered'] = (pass_df.dist_def < dist_def_cutoff).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_df.sort_values('dist_def', ascending=True).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get the height of each player (target and defender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert player height into consistent format (inches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ftin_to_in(ftin):\n",
    "    # converts ft-in notation to inches (i.e. 6-2 to 74)\n",
    "    [f, i] = ftin.split('-')\n",
    "    return 12 * int(f) + int(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_ftin = player_df.height.str.contains('-')\n",
    "player_df.loc[ind_ftin, 'height'] = player_df.height[ind_ftin].apply(ftin_to_in)\n",
    "player_df.loc[:, 'height'] = player_df.height.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_df.height.value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the height of target and defender to dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add targeted player:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_df = pd.merge(pass_df, target_df.rename(columns={'targetNflId': 'nflId_target'}),\n",
    "        how='left',\n",
    "        on=['gameId','playId'])\n",
    "pass_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add defender height:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_df = pd.merge(pass_df, player_df[['nflId', 'height']].rename(columns={'nflId': 'nflId_def', 'height': 'def_height'}),\n",
    "                   how='left',\n",
    "                   on='nflId_def'\n",
    "                  )\n",
    "pass_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add targeted player height:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_df = pd.merge(pass_df, player_df[['nflId', 'height']].rename(columns={'nflId': 'nflId_target', 'height': 'tgt_height'}),\n",
    "                   how='left',\n",
    "                   on='nflId_target'\n",
    "                  )\n",
    "pass_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a. Calculate the height difference between each player "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the height difference between receiver and defender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'tgt_height_adv' = target height advantage (target - defender)\n",
    "pass_df['tgt_height_adv'] = pass_df.tgt_height - pass_df.def_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_df.tgt_height_adv.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "sns.countplot(data=pass_df, x='tgt_height_adv')\n",
    "print(pass_df.tgt_height_adv.value_counts().sort_index(ascending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping together the values <= -7 and >= 8 will group the extremes to roughly 200 pass plays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group together extreme values\n",
    "min_bin_bound = -7\n",
    "max_bin_bound = 8\n",
    "pass_df['tgt_height_adv_bin'] = pass_df.tgt_height_adv\n",
    "pass_df.loc[pass_df.tgt_height_adv <= min_bin_bound, 'tgt_height_adv_bin'] = min_bin_bound\n",
    "pass_df.loc[pass_df.tgt_height_adv >= max_bin_bound, 'tgt_height_adv_bin'] = max_bin_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Calculate passing performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_df = pd.merge(pass_df, play_df,\n",
    "                  on=['gameId', 'playId'],\n",
    "                  how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(data=pass_df, x='tgt_height_adv_bin', y='epa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11,6))\n",
    "sns.barplot(data=pass_df, x='tgt_height_adv_bin', y='epa', ci=None, color='b')\n",
    "plt.title('Mean EPA of All Pass Attempts vs. Height Difference');\n",
    "plt.ylabel('EPA')\n",
    "plt.xlabel('Target Height Advantage (in)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completion Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column to aid calculating yards per completion\n",
    "pass_df['yds_cmp'] = np.nan  # NaN for incomplete\n",
    "pass_df.loc[pass_df.passResult=='C', 'yds_cmp'] = pass_df.loc[pass_df.passResult=='C', 'offensePlayResult']\n",
    "\n",
    "# compute aggregates\n",
    "cmp_agg = pass_df[~pass_df.playDescription.str.contains('No Play')].groupby('tgt_height_adv_bin').agg(\n",
    "    count=pd.NamedAgg(column='playId', aggfunc='count'),\n",
    "    cmp_pct=pd.NamedAgg(column='passResult', aggfunc=lambda ser: np.sum(ser=='C') / len(ser)),\n",
    "    yd_per_att=pd.NamedAgg(column='offensePlayResult', aggfunc='mean'),\n",
    "    yd_per_cmp=pd.NamedAgg(column='yds_cmp', aggfunc=np.nanmean)\n",
    ").reset_index()\n",
    "cmp_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=cmp_agg, x='tgt_height_adv_bin', y='cmp_pct');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=cmp_agg, x='tgt_height_adv_bin', y='yd_per_att');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=cmp_agg, x='tgt_height_adv_bin', y='yd_per_cmp');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an interesting trend. Need to group together ends due to low value counts, but this goes against the typical wisdom of height advantage. Need to look to see average depth of pass to see if high mismatch is from short RB/speedsters catching in open space rather than truly beating coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth of pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute aggregates\n",
    "dop_agg = pass_df[~pass_df.playDescription.str.contains('No Play')].groupby('tgt_height_adv_bin').agg(\n",
    "    count=pd.NamedAgg(column='playId', aggfunc='count'),\n",
    "    pass_depth_mean=pd.NamedAgg(column='pass_depth', aggfunc=np.nanmean),\n",
    "    pass_depth_median=pd.NamedAgg(column='pass_depth', aggfunc=np.nanmedian),\n",
    ").reset_index()\n",
    "dop_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(data=pass_df, x='tgt_height_adv_bin', y='pass_depth');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=dop_agg, x='tgt_height_adv_bin', y='pass_depth_median');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEXT UP: Look at completion pctg. vs. depth of pass to determine if there is a height advantage that performs better than expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Completion percentage vs. depth of pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_depth_df = pd.merge(closest_def_df[['gameId','playId','pass_depth']],\n",
    "                         play_df[['gameId','playId','passResult']])\n",
    "comp_depth_df.dropna(inplace=True)\n",
    "comp_depth_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_depth_df.passResult.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add flag for complete vs not complete\n",
    "comp_depth_df['comp'] = (comp_depth_df.passResult=='C').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the distribution of the pass depth looking at multiple bin widths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_depth = -6  # all below this value will be binned together\n",
    "max_depth = 36 # all above this value will be binned together\n",
    "bin_width = 3  # yards\n",
    "\n",
    "depth_bins = np.concatenate([np.array([-100]), np.arange(min_depth, max_depth + 0.01, bin_width), np.array([100])])\n",
    "# define the depth to use for regression (middle of the bin, except for the ends which will use a cutoff)\n",
    "depth_points_mid = (depth_bins[1:-2] + depth_bins[2:-1]) / 2\n",
    "# first and last points are temporary\n",
    "depth_points = np.concatenate([np.array([-100]), depth_points_mid, np.array([100])])\n",
    "# set first and last points to the mean value for the extreme bins\n",
    "depth_points[0] = comp_depth_df.loc[comp_depth_df.pass_depth <= min_depth, 'pass_depth'].mean()\n",
    "depth_points[-1] = comp_depth_df.loc[comp_depth_df.pass_depth > max_depth, 'pass_depth'].mean()\n",
    "\n",
    "sns.displot(data=comp_depth_df, x='pass_depth', bins=depth_bins, kind='hist')\n",
    "plt.axhline(100, color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_depth_df['pass_depth_bin'] = pd.cut(comp_depth_df['pass_depth'], depth_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the completion percentage in each bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_depth_agg = comp_depth_df.groupby('pass_depth_bin').agg(\n",
    "    comp_pct=pd.NamedAgg(column='comp', aggfunc='mean')\n",
    ")\n",
    "comp_depth_agg['depth_point'] = depth_points\n",
    "comp_depth_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "ax = plt.gcf().gca()\n",
    "sns.scatterplot(data=comp_depth_agg, x='depth_point', y='comp_pct')\n",
    "plt.xlabel('Pass Attempt Depth (yds)')\n",
    "plt.ylabel('Completion Percentage')\n",
    "plt.title(f'2018 Aggregate Completion Percentage by Pass Attempt Depth, Relative to LOS ({bin_width}-yd Bins)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling the completion percentage vs. pass attempt depth as a logistic curve (asymptotes at extremes) makes sense: behind line of scrimmage passes are easy, increasing difficulty as depth increases, then reaches a \"natural\" completion rate when passes are over 35 yards (the marginal difficulty for increasingly long throws is near zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_fcn(depth, a, b, k, q, v):\n",
    "    return a + (k - a) / ((1 + q * np.exp(-b * depth)) ** (1/v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters (a,b,k,q,v)\n",
    "p0 = np.array([.85, .05, .25, .25, 1])\n",
    "log_bounds = ([0, 0, 0, 0, .00000000001], [1, 3, 1, 1000, 10])\n",
    "\n",
    "x = comp_depth_agg.depth_point.to_numpy()\n",
    "y = comp_depth_agg.comp_pct.to_numpy()\n",
    "cmp_model_params, _ = optim.curve_fit(logistic_fcn, x, y, bounds=log_bounds, p0=p0)\n",
    "cmp_model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a handle to the completion percentage model\n",
    "cmp_pct_model = lambda depth: logistic_fcn(depth, *cmp_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_curve = np.linspace(-20, 60, 500)\n",
    "cmp_curve = cmp_pct_model(x_curve)\n",
    "\n",
    "# plot the data\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(x, y, marker='o', linestyle='')\n",
    "plt.plot(x_curve, cmp_curve, linestyle='-', marker=None, color='k')\n",
    "plt.xlabel('Pass Attempt Depth (yds)')\n",
    "plt.ylabel('Completion Percentage')\n",
    "plt.title(f'2018 Aggregate Completion Percentage by Pass Attempt Depth, Relative to LOS ({bin_width}-yd Bins)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp_predict = cmp_pct_model(x)\n",
    "resid = cmp_predict - y\n",
    "plt.figure()\n",
    "plt.plot(x, resid, marker='o', ls='')\n",
    "plt.axhline(0, ls='--', c='gray')\n",
    "plt.xlabel('Pass Attempt Depth (yds)')\n",
    "plt.ylabel('Residual (Percentage Points)')\n",
    "plt.title('Completion Percentage Logistic Regression Residuals');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit is within a few percentage points below 25 yards, which is good enough for a comparative analysis of individual players."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Compare Cmp Pct Above Average (CPOA) between players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the completion percentage for each play of the season:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpoa_df = pass_df[['gameId','playId','nflId_def','pass_depth','zone','covered','passResult','epa']].copy().dropna()\n",
    "cpoa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the expected completion percentage\n",
    "cpoa_df['cp_expect'] = cmp_pct_model(cpoa_df.pass_depth)\n",
    "\n",
    "# remove the plays where there wasn't really coverage (very soft zone)\n",
    "cpoa_df = cpoa_df[cpoa_df.covered==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the number of players that would remain if a particular play count is used as a minimum filter\n",
    "n_plays = cpoa_df.groupby('nflId_def').agg('count')['gameId'].to_numpy()\n",
    "play_range = np.arange(5,100,5)\n",
    "n_players = []\n",
    "\n",
    "for p in play_range:\n",
    "    n_players.append(np.sum(n_plays >= p))\n",
    "    \n",
    "plt.figure()\n",
    "plt.scatter(play_range, n_players, ls='--', marker='o')\n",
    "plt.xlabel('Minimum Plays')\n",
    "plt.ylabel('Players')\n",
    "plt.title('Number of Players Remaining after Minimum Play Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 30 as a cutoff is reasonable and leaves over 200 players left to analyze. This also leaves rooms for high-level players that are not target often by design (~2 targets/game)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cutoff = 30\n",
    "\n",
    "# aggregate on defensive players with minimum targets >= n_cutoff\n",
    "cpoa_df = cpoa_df.groupby('nflId_def').filter(lambda df: len(df) >= n_cutoff)\n",
    "\n",
    "cpoa_agg = cpoa_df.groupby('nflId_def').agg(\n",
    "    plays_total = pd.NamedAgg(column='passResult', aggfunc=len),\n",
    "    plays_zone = pd.NamedAgg(column='zone', aggfunc=lambda x: np.sum(x==1)),\n",
    "    plays_man = pd.NamedAgg(column='zone', aggfunc=lambda x: np.sum(x==0)),\n",
    "    epa_avg_tot = pd.NamedAgg(column='epa', aggfunc='mean'),\n",
    "    cp = pd.NamedAgg(column='passResult', aggfunc=lambda x: np.mean(x=='C')),\n",
    "    cp_expect = pd.NamedAgg(column='cp_expect', aggfunc='mean'),\n",
    ").reset_index()\n",
    "\n",
    "# make play count columns integers\n",
    "cpoa_agg['plays_zone'] = cpoa_agg.plays_zone.astype(int)\n",
    "cpoa_agg['plays_man'] = cpoa_agg.plays_man.astype(int)\n",
    "\n",
    "# calculate CPOA\n",
    "cpoa_agg['cpoa'] = cpoa_agg.cp_expect - cpoa_agg.cp\n",
    "\n",
    "cpoa_agg = pd.merge(cpoa_agg, player_df[['nflId','displayName','position']], \n",
    "                   left_on='nflId_def', right_on='nflId', how='left').drop(columns='nflId')\n",
    "cpoa_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the average EPA for zone vs. man coverage\n",
    "epa_agg = cpoa_df.groupby(['nflId_def', 'zone']).agg(\n",
    "    epa_avg = pd.NamedAgg(column='epa', aggfunc='mean')\n",
    ").unstack()\n",
    "epa_agg.columns=['epa_avg_man', 'epa_avg_zone']\n",
    "epa_agg.reset_index(inplace=True)\n",
    "epa_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add EPA breakdown into cpoa dataframe\n",
    "cpoa_agg = pd.merge(cpoa_agg, epa_agg, on='nflId_def')\n",
    "cpoa_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpoa_agg[cpoa_agg.position.isin(['CB','DB'])].sort_values('cpoa', ascending=False).head(15)\n",
    "cpoa_agg[cpoa_agg.position.isin(['CB','DB'])].sort_values('cpoa', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpoa_agg[['plays_zone','plays_man']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpoa_agg.sort_values('plays_man', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------- MISC CALCULATIONS ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df.loc[track_df.event=='pass_outcome_interception', ['gameId','playId','event','frameId']].groupby(['gameId','playId']).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gid = 2018121605\n",
    "pid = 3489\n",
    "temp = (track_df.loc[(track_df.gameId==gid) & (track_df.playId==pid), ['gameId','playId','event','frameId']]\n",
    " .groupby('frameId').head(1))\n",
    "\n",
    "temp.loc[temp.event!='None', ['event','frameId']].apply(tuple, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -------- Play outcome ---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "play_df[~play_df.penaltyCodes.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_df.passResult.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, p in play_df[play_df.penaltyCodes=='DPI'].iterrows():\n",
    "#     print(p)\n",
    "    print(f\"[{p.gameId}, {p.playId}] {p.playDescription}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_id=2018090900\n",
    "play_id=742\n",
    "play_df[(play_df.gameId==game_id) & (play_df.playId == play_id)].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_df[play_df.playDescription.str.contains(\"No Play.\")].penaltyCodes.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.merge(target_df, player_df.rename(columns={'nflId': 'targetNflId'}), how='left', on='targetNflId')\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_df.coverage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df.event.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = track_df.groupby(['playId','gameId']).apply(lambda df: np.any(df.event == 'pass_forward') & np.all(df.event != 'pass_arrived')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df[out_df[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = []\n",
    "\n",
    "for pid, gid in zip(out_df[out_df[0]].playId, out_df[out_df[0]].gameId):\n",
    "    # get events for given play and game ID\n",
    "    play_events = track_df[(track_df.gameId == gid) & (track_df.playId == pid)].event.unique()\n",
    "    if np.any(play_events == 'pass_forward'):\n",
    "        # get index of pass_forward to grab any events that occur afterwards\n",
    "        idx_pass_fwd = np.where(play_events == 'pass_forward')[0][0]\n",
    "        if len(play_events)-1 > idx_pass_fwd:\n",
    "            # get all events after the forward pass event\n",
    "            after_pass_events = play_events[idx_pass_fwd+1:].tolist()\n",
    "            if after_pass_events not in events:\n",
    "                events.append(after_pass_events)\n",
    "    \n",
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_id = 2018121605\n",
    "play_id = 1770\n",
    "track_df[(track_df.gameId == game_id) & (track_df.playId == play_id)].event.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_end_events = ['pass_arrived', 'pass_outcome_interception', 'pass_outcome_incomplete', 'pass_outcome_caught']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PASS_END_EVENTS = ['pass_arrived',\n",
    "                       'pass_outcome_interception',\n",
    "                       'pass_outcome_incomplete',\n",
    "                       'pass_outcome_caught']\n",
    "PASS_END_EVENTS = ['fake_bad_event']\n",
    "track_df.loc[track_df.event.isin(PASS_END_EVENTS), 'frameId'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_df[(play_df.gameId.isin([2018111111, 2018121604])) & (play_df.playId.isin([2502, 1333]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df[(game_df.gameId.isin([2018111111, 2018121604]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=pd.merge(play_df, game_df, on='gameId')\n",
    "z.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.typeDropback.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_plays = pd.merge(coverage_df, track_df.groupby(['gameId','playId']).head(1)[['gameId','playId']],\n",
    "        on=['gameId','playId'], how='inner')[['gameId','playId']]\n",
    "\n",
    "non_unknown_plays = play_df[play_df.typeDropback!='UNKNOWN']\n",
    "\n",
    "remaining_plays = pd.merge(cover_plays, non_unknown_plays, on=['gameId','playId'], how='inner')\n",
    "\n",
    "remaining_plays.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for desc in z[(z.week==1) & (z.typeDropback=='UNKNOWN')]['playDescription']:\n",
    "    print(desc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
